{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Subreddit Pages: Nike or Adidas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared by: Jessie Owens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Problem Statement](#Problem_Statement)\n",
    "- [Description of Data](#Description_of_Data)\n",
    "- [Import Libraries](#Import_Libraries)\n",
    "- [EDA](#EDA)\n",
    "- [Modeling](#Modeling)\n",
    "- [Conclusions & Next Steps](#Conclusions_&_Next_Steps)\n",
    "- [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does marketing language influence online conversations about products? I was curious about two things:\n",
    "1. If you remove the brand name and product names from the text, can we predict the brand that an online post is discussing using an NLP model? \n",
    "2. How does the language that is used in a marketing campaign influence the way a brand’s critics and supporters choose to talk about that brand in an online setting? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data included in this analysis was pulled from https://www.reddit.com and includes posts from two subreddit pages:\n",
    "- /r/Nike\n",
    "- /r/adidas\n",
    "\n",
    "The data collection process was completed in another [Jupyter Notebook](./reddit_data_collection.ipynb).\n",
    "\n",
    "There were 4120 total posts pulled from the two subreddit pages, including 1992 from the Nike subreddit and 2128 from the Adidas subreddit. The posts are from December 20, 2018 to October 15, 2019. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jessieowens2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jessieowens2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import regex as re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from bs4 import BeautifulSoup             \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the brands data compiled in a sparate JN\n",
    "brands = pd.read_csv('./data/brands.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Are womens sizes the same as mens for Nike M2K...</td>\n",
       "      <td>There is a particular colour of Nike M2K train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Laces</td>\n",
       "      <td>What kind of laces does the FoG Raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Sizing question on buying men’s for women. Siz...</td>\n",
       "      <td>Soo I had been eyeing the women’s Nike Air Max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Trying to remember a hoodie or shirt Drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Thankyou to my Nike tanjuns</td>\n",
       "      <td>http://imgur.com/a/uVOw8g8\\n\\nThey lasted me s...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Are womens sizes the same as mens for Nike M2K...   \n",
       "1           1                                              Laces   \n",
       "2           2  Sizing question on buying men’s for women. Siz...   \n",
       "3           3    Trying to remember a hoodie or shirt Drake wore   \n",
       "4           4                        Thankyou to my Nike tanjuns   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  There is a particular colour of Nike M2K train...      Nike   1568401703   \n",
       "1  What kind of laces does the FoG Raid comes wit...      Nike   1568406910   \n",
       "2  Soo I had been eyeing the women’s Nike Air Max...      Nike   1568443108   \n",
       "3  i remember seeing pictures of drake wearing a ...      Nike   1568486842   \n",
       "4  http://imgur.com/a/uVOw8g8\\n\\nThey lasted me s...      Nike   1568497739   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \n",
       "0  johnnyredneat             1      0     True  2019-09-13  \n",
       "1    Hoxton_0451             0      0     True  2019-09-13  \n",
       "2    buzzbuzzbih             3      0     True  2019-09-14  \n",
       "3  perpetualpies             3      0     True  2019-09-14  \n",
       "4   adeptwarrior             0      0     True  2019-09-14  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4120, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adidas    2128\n",
       "Nike      1992\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4115</td>\n",
       "      <td>12</td>\n",
       "      <td>Nike Promo Codes?</td>\n",
       "      <td>Does anyone have any online Nike promo codes? ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562776770</td>\n",
       "      <td>titi321</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4116</td>\n",
       "      <td>0</td>\n",
       "      <td>Best Nikes for standing all day?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562636033</td>\n",
       "      <td>parksandtheoffice</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4117</td>\n",
       "      <td>5</td>\n",
       "      <td>Stranger things drop at 8am, is that west coas...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562659979</td>\n",
       "      <td>xColaDoo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4118</td>\n",
       "      <td>12</td>\n",
       "      <td>ID on these Nike high tops</td>\n",
       "      <td>&amp;amp;#x200B;\\n\\nhttps://i.redd.it/p0f1ju1z6b93...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562691617</td>\n",
       "      <td>GuyNamedNoah</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4119</td>\n",
       "      <td>16</td>\n",
       "      <td>Trying to find a Nike ad</td>\n",
       "      <td>Saw a Nike ad (few weeks back I think?) Where ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562699201</td>\n",
       "      <td>TopNotchGamerr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "4115          12                                  Nike Promo Codes?   \n",
       "4116           0                   Best Nikes for standing all day?   \n",
       "4117           5  Stranger things drop at 8am, is that west coas...   \n",
       "4118          12                         ID on these Nike high tops   \n",
       "4119          16                           Trying to find a Nike ad   \n",
       "\n",
       "                                               selftext subreddit  \\\n",
       "4115  Does anyone have any online Nike promo codes? ...      Nike   \n",
       "4116                                                NaN      Nike   \n",
       "4117                                              Title      Nike   \n",
       "4118  &amp;#x200B;\\n\\nhttps://i.redd.it/p0f1ju1z6b93...      Nike   \n",
       "4119  Saw a Nike ad (few weeks back I think?) Where ...      Nike   \n",
       "\n",
       "      created_utc             author  num_comments  score  is_self   timestamp  \n",
       "4115   1562776770            titi321             2      0     True  2019-07-10  \n",
       "4116   1562636033  parksandtheoffice             2      1     True  2019-07-08  \n",
       "4117   1562659979           xColaDoo             1      0     True  2019-07-09  \n",
       "4118   1562691617       GuyNamedNoah             0      1     True  2019-07-09  \n",
       "4119   1562699201     TopNotchGamerr             0      1     True  2019-07-09  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "title             0\n",
       "selftext        360\n",
       "subreddit         0\n",
       "created_utc       0\n",
       "author            0\n",
       "num_comments      0\n",
       "score             0\n",
       "is_self           0\n",
       "timestamp         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 13)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adidas    1953\n",
       "Nike      1807\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adidas    0.519415\n",
       "Nike      0.480585\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Are womens sizes the same as mens for Nike M2K...</td>\n",
       "      <td>There is a particular colour of Nike M2K train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Laces</td>\n",
       "      <td>What kind of laces does the FoG Raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sizing question on buying men’s for women. Siz...</td>\n",
       "      <td>Soo I had been eyeing the women’s Nike Air Max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trying to remember a hoodie or shirt Drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Thankyou to my Nike tanjuns</td>\n",
       "      <td>http://imgur.com/a/uVOw8g8\\n\\nThey lasted me s...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Are womens sizes the same as mens for Nike M2K...   \n",
       "1                                              Laces   \n",
       "2  Sizing question on buying men’s for women. Siz...   \n",
       "3    Trying to remember a hoodie or shirt Drake wore   \n",
       "4                        Thankyou to my Nike tanjuns   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  There is a particular colour of Nike M2K train...      Nike   1568401703   \n",
       "1  What kind of laces does the FoG Raid comes wit...      Nike   1568406910   \n",
       "2  Soo I had been eyeing the women’s Nike Air Max...      Nike   1568443108   \n",
       "3  i remember seeing pictures of drake wearing a ...      Nike   1568486842   \n",
       "4  http://imgur.com/a/uVOw8g8\\n\\nThey lasted me s...      Nike   1568497739   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \n",
       "0  johnnyredneat             1      0     True  2019-09-13  \n",
       "1    Hoxton_0451             0      0     True  2019-09-13  \n",
       "2    buzzbuzzbih             3      0     True  2019-09-14  \n",
       "3  perpetualpies             3      0     True  2019-09-14  \n",
       "4   adeptwarrior             0      0     True  2019-09-14  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop author\n",
    "# brands.drop('author', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does anyone know how big the huarache drift air unit is or how does it look like?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands['selftext'][800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not doing any HTML cleaning because seems to not be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_brands = brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"%\", \"percent\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\_\\\\n]\", \" \")\n",
    "#     df[text_field] = df[text_field].str.replace(r\"\\\\n\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "#     df[text_field] = df[text_field].str.replace(r\"13 5\", \"thirteenhalf\")\n",
    "#     df[text_field] = df[text_field].str.replace(r\"14\", \"fourteen\")\n",
    "#     df[text_field] = df[text_field].str.replace(r\"11\", \"eleven\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df\n",
    "\n",
    "# got this function from Emmanuel Ameisen's blog post on NLP: \n",
    "# https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Are womens sizes the same as mens for Nike M2K...</td>\n",
       "      <td>there is a particular colour of nike m2k train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Laces</td>\n",
       "      <td>what kind of laces does the fog raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sizing question on buying men’s for women. Siz...</td>\n",
       "      <td>soo i had been eyeing the women s nike air max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trying to remember a hoodie or shirt Drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Thankyou to my Nike tanjuns</td>\n",
       "      <td>they lasted me since 2015  5 years service a...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4114</td>\n",
       "      <td>Where can I find these Jordan basketball short...</td>\n",
       "      <td>not sure what these are called or if it s even...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562757768</td>\n",
       "      <td>Curious_George_Asks</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4115</td>\n",
       "      <td>Nike Promo Codes?</td>\n",
       "      <td>does anyone have any online nike promo codes? ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562776770</td>\n",
       "      <td>titi321</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4117</td>\n",
       "      <td>Stranger things drop at 8am, is that west coas...</td>\n",
       "      <td>title</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562659979</td>\n",
       "      <td>xColaDoo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4118</td>\n",
       "      <td>ID on these Nike high tops</td>\n",
       "      <td>amp  x200b</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562691617</td>\n",
       "      <td>GuyNamedNoah</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4119</td>\n",
       "      <td>Trying to find a Nike ad</td>\n",
       "      <td>saw a nike ad (few weeks back i think?) where ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562699201</td>\n",
       "      <td>TopNotchGamerr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Are womens sizes the same as mens for Nike M2K...   \n",
       "1                                                 Laces   \n",
       "2     Sizing question on buying men’s for women. Siz...   \n",
       "3       Trying to remember a hoodie or shirt Drake wore   \n",
       "4                           Thankyou to my Nike tanjuns   \n",
       "...                                                 ...   \n",
       "4114  Where can I find these Jordan basketball short...   \n",
       "4115                                  Nike Promo Codes?   \n",
       "4117  Stranger things drop at 8am, is that west coas...   \n",
       "4118                         ID on these Nike high tops   \n",
       "4119                           Trying to find a Nike ad   \n",
       "\n",
       "                                               selftext subreddit  \\\n",
       "0     there is a particular colour of nike m2k train...      Nike   \n",
       "1     what kind of laces does the fog raid comes wit...      Nike   \n",
       "2     soo i had been eyeing the women s nike air max...      Nike   \n",
       "3     i remember seeing pictures of drake wearing a ...      Nike   \n",
       "4       they lasted me since 2015  5 years service a...      Nike   \n",
       "...                                                 ...       ...   \n",
       "4114  not sure what these are called or if it s even...      Nike   \n",
       "4115  does anyone have any online nike promo codes? ...      Nike   \n",
       "4117                                              title      Nike   \n",
       "4118                                      amp  x200b         Nike   \n",
       "4119  saw a nike ad (few weeks back i think?) where ...      Nike   \n",
       "\n",
       "      created_utc               author  num_comments  score  is_self  \\\n",
       "0      1568401703        johnnyredneat             1      0     True   \n",
       "1      1568406910          Hoxton_0451             0      0     True   \n",
       "2      1568443108          buzzbuzzbih             3      0     True   \n",
       "3      1568486842        perpetualpies             3      0     True   \n",
       "4      1568497739         adeptwarrior             0      0     True   \n",
       "...           ...                  ...           ...    ...      ...   \n",
       "4114   1562757768  Curious_George_Asks             0      2     True   \n",
       "4115   1562776770              titi321             2      0     True   \n",
       "4117   1562659979             xColaDoo             1      0     True   \n",
       "4118   1562691617         GuyNamedNoah             0      1     True   \n",
       "4119   1562699201       TopNotchGamerr             0      1     True   \n",
       "\n",
       "       timestamp  \n",
       "0     2019-09-13  \n",
       "1     2019-09-13  \n",
       "2     2019-09-14  \n",
       "3     2019-09-14  \n",
       "4     2019-09-14  \n",
       "...          ...  \n",
       "4114  2019-07-10  \n",
       "4115  2019-07-10  \n",
       "4117  2019-07-09  \n",
       "4118  2019-07-09  \n",
       "4119  2019-07-09  \n",
       "\n",
       "[3760 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_text(cleaned_brands, 'selftext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>are womens sizes the same as mens for nike m2k...</td>\n",
       "      <td>there is a particular colour of nike m2k train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>laces</td>\n",
       "      <td>what kind of laces does the fog raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sizing question on buying men s for women  siz...</td>\n",
       "      <td>soo i had been eyeing the women s nike air max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>trying to remember a hoodie or shirt drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thankyou to my nike tanjuns</td>\n",
       "      <td>they lasted me since 2015  5 years service a...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4114</td>\n",
       "      <td>where can i find these jordan basketball short...</td>\n",
       "      <td>not sure what these are called or if it s even...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562757768</td>\n",
       "      <td>Curious_George_Asks</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4115</td>\n",
       "      <td>nike promo codes?</td>\n",
       "      <td>does anyone have any online nike promo codes? ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562776770</td>\n",
       "      <td>titi321</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4117</td>\n",
       "      <td>stranger things drop at 8am, is that west coas...</td>\n",
       "      <td>title</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562659979</td>\n",
       "      <td>xColaDoo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4118</td>\n",
       "      <td>id on these nike high tops</td>\n",
       "      <td>amp  x200b</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562691617</td>\n",
       "      <td>GuyNamedNoah</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4119</td>\n",
       "      <td>trying to find a nike ad</td>\n",
       "      <td>saw a nike ad (few weeks back i think?) where ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562699201</td>\n",
       "      <td>TopNotchGamerr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     are womens sizes the same as mens for nike m2k...   \n",
       "1                                                 laces   \n",
       "2     sizing question on buying men s for women  siz...   \n",
       "3       trying to remember a hoodie or shirt drake wore   \n",
       "4                           thankyou to my nike tanjuns   \n",
       "...                                                 ...   \n",
       "4114  where can i find these jordan basketball short...   \n",
       "4115                                  nike promo codes?   \n",
       "4117  stranger things drop at 8am, is that west coas...   \n",
       "4118                         id on these nike high tops   \n",
       "4119                           trying to find a nike ad   \n",
       "\n",
       "                                               selftext subreddit  \\\n",
       "0     there is a particular colour of nike m2k train...      Nike   \n",
       "1     what kind of laces does the fog raid comes wit...      Nike   \n",
       "2     soo i had been eyeing the women s nike air max...      Nike   \n",
       "3     i remember seeing pictures of drake wearing a ...      Nike   \n",
       "4       they lasted me since 2015  5 years service a...      Nike   \n",
       "...                                                 ...       ...   \n",
       "4114  not sure what these are called or if it s even...      Nike   \n",
       "4115  does anyone have any online nike promo codes? ...      Nike   \n",
       "4117                                              title      Nike   \n",
       "4118                                      amp  x200b         Nike   \n",
       "4119  saw a nike ad (few weeks back i think?) where ...      Nike   \n",
       "\n",
       "      created_utc               author  num_comments  score  is_self  \\\n",
       "0      1568401703        johnnyredneat             1      0     True   \n",
       "1      1568406910          Hoxton_0451             0      0     True   \n",
       "2      1568443108          buzzbuzzbih             3      0     True   \n",
       "3      1568486842        perpetualpies             3      0     True   \n",
       "4      1568497739         adeptwarrior             0      0     True   \n",
       "...           ...                  ...           ...    ...      ...   \n",
       "4114   1562757768  Curious_George_Asks             0      2     True   \n",
       "4115   1562776770              titi321             2      0     True   \n",
       "4117   1562659979             xColaDoo             1      0     True   \n",
       "4118   1562691617         GuyNamedNoah             0      1     True   \n",
       "4119   1562699201       TopNotchGamerr             0      1     True   \n",
       "\n",
       "       timestamp  \n",
       "0     2019-09-13  \n",
       "1     2019-09-13  \n",
       "2     2019-09-14  \n",
       "3     2019-09-14  \n",
       "4     2019-09-14  \n",
       "...          ...  \n",
       "4114  2019-07-10  \n",
       "4115  2019-07-10  \n",
       "4117  2019-07-09  \n",
       "4118  2019-07-09  \n",
       "4119  2019-07-09  \n",
       "\n",
       "[3760 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_text(cleaned_brands, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS??\n",
    "#     # 4. In Python, searching a set is much faster than searching\n",
    "#     # a list, so convert the stop words to a set.\n",
    "#     stops = set(stopwords.words('english'))\n",
    "    \n",
    "#     # 5. Remove stop words.\n",
    "#     meaningful_words = [w for w in words if w not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3760 posts.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of posts based on the dataframe size.\n",
    "total_posts = cleaned_brands.shape[0]\n",
    "print(f'There are {total_posts} posts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>are womens sizes the same as mens for nike m2k...</td>\n",
       "      <td>there is a particular colour of nike m2k train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>laces</td>\n",
       "      <td>what kind of laces does the fog raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sizing question on buying men s for women  siz...</td>\n",
       "      <td>soo i had been eyeing the women s nike air max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>trying to remember a hoodie or shirt drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thankyou to my nike tanjuns</td>\n",
       "      <td>they lasted me since 2015  5 years service a...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  are womens sizes the same as mens for nike m2k...   \n",
       "1                                              laces   \n",
       "2  sizing question on buying men s for women  siz...   \n",
       "3    trying to remember a hoodie or shirt drake wore   \n",
       "4                        thankyou to my nike tanjuns   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  there is a particular colour of nike m2k train...      Nike   1568401703   \n",
       "1  what kind of laces does the fog raid comes wit...      Nike   1568406910   \n",
       "2  soo i had been eyeing the women s nike air max...      Nike   1568443108   \n",
       "3  i remember seeing pictures of drake wearing a ...      Nike   1568486842   \n",
       "4    they lasted me since 2015  5 years service a...      Nike   1568497739   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \n",
       "0  johnnyredneat             1      0     True  2019-09-13  \n",
       "1    Hoxton_0451             0      0     True  2019-09-13  \n",
       "2    buzzbuzzbih             3      0     True  2019-09-14  \n",
       "3  perpetualpies             3      0     True  2019-09-14  \n",
       "4   adeptwarrior             0      0     True  2019-09-14  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_brands['title_tokens'] = cleaned_brands['title'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>are womens sizes the same as mens for nike m2k...</td>\n",
       "      <td>there is a particular colour of nike m2k train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>[are, womens, sizes, the, same, as, mens, for,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>laces</td>\n",
       "      <td>what kind of laces does the fog raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>[laces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sizing question on buying men s for women  siz...</td>\n",
       "      <td>soo i had been eyeing the women s nike air max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[sizing, question, on, buying, men, s, for, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>trying to remember a hoodie or shirt drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[trying, to, remember, a, hoodie, or, shirt, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thankyou to my nike tanjuns</td>\n",
       "      <td>they lasted me since 2015  5 years service a...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[thankyou, to, my, nike, tanjuns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  are womens sizes the same as mens for nike m2k...   \n",
       "1                                              laces   \n",
       "2  sizing question on buying men s for women  siz...   \n",
       "3    trying to remember a hoodie or shirt drake wore   \n",
       "4                        thankyou to my nike tanjuns   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  there is a particular colour of nike m2k train...      Nike   1568401703   \n",
       "1  what kind of laces does the fog raid comes wit...      Nike   1568406910   \n",
       "2  soo i had been eyeing the women s nike air max...      Nike   1568443108   \n",
       "3  i remember seeing pictures of drake wearing a ...      Nike   1568486842   \n",
       "4    they lasted me since 2015  5 years service a...      Nike   1568497739   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \\\n",
       "0  johnnyredneat             1      0     True  2019-09-13   \n",
       "1    Hoxton_0451             0      0     True  2019-09-13   \n",
       "2    buzzbuzzbih             3      0     True  2019-09-14   \n",
       "3  perpetualpies             3      0     True  2019-09-14   \n",
       "4   adeptwarrior             0      0     True  2019-09-14   \n",
       "\n",
       "                                        title_tokens  \n",
       "0  [are, womens, sizes, the, same, as, mens, for,...  \n",
       "1                                            [laces]  \n",
       "2  [sizing, question, on, buying, men, s, for, wo...  \n",
       "3  [trying, to, remember, a, hoodie, or, shirt, d...  \n",
       "4                  [thankyou, to, my, nike, tanjuns]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_brands['text_tokens'] = cleaned_brands['selftext'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>are womens sizes the same as mens for nike m2k...</td>\n",
       "      <td>there is a particular colour of nike m2k train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>[are, womens, sizes, the, same, as, mens, for,...</td>\n",
       "      <td>[there, is, a, particular, colour, of, nike, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>laces</td>\n",
       "      <td>what kind of laces does the fog raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>[laces]</td>\n",
       "      <td>[what, kind, of, laces, does, the, fog, raid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sizing question on buying men s for women  siz...</td>\n",
       "      <td>soo i had been eyeing the women s nike air max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[sizing, question, on, buying, men, s, for, wo...</td>\n",
       "      <td>[soo, i, had, been, eyeing, the, women, s, nik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>trying to remember a hoodie or shirt drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[trying, to, remember, a, hoodie, or, shirt, d...</td>\n",
       "      <td>[i, remember, seeing, pictures, of, drake, wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thankyou to my nike tanjuns</td>\n",
       "      <td>they lasted me since 2015  5 years service a...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[thankyou, to, my, nike, tanjuns]</td>\n",
       "      <td>[they, lasted, me, since, 2015, 5, years, serv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  are womens sizes the same as mens for nike m2k...   \n",
       "1                                              laces   \n",
       "2  sizing question on buying men s for women  siz...   \n",
       "3    trying to remember a hoodie or shirt drake wore   \n",
       "4                        thankyou to my nike tanjuns   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  there is a particular colour of nike m2k train...      Nike   1568401703   \n",
       "1  what kind of laces does the fog raid comes wit...      Nike   1568406910   \n",
       "2  soo i had been eyeing the women s nike air max...      Nike   1568443108   \n",
       "3  i remember seeing pictures of drake wearing a ...      Nike   1568486842   \n",
       "4    they lasted me since 2015  5 years service a...      Nike   1568497739   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \\\n",
       "0  johnnyredneat             1      0     True  2019-09-13   \n",
       "1    Hoxton_0451             0      0     True  2019-09-13   \n",
       "2    buzzbuzzbih             3      0     True  2019-09-14   \n",
       "3  perpetualpies             3      0     True  2019-09-14   \n",
       "4   adeptwarrior             0      0     True  2019-09-14   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  [are, womens, sizes, the, same, as, mens, for,...   \n",
       "1                                            [laces]   \n",
       "2  [sizing, question, on, buying, men, s, for, wo...   \n",
       "3  [trying, to, remember, a, hoodie, or, shirt, d...   \n",
       "4                  [thankyou, to, my, nike, tanjuns]   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [there, is, a, particular, colour, of, nike, m...  \n",
       "1  [what, kind, of, laces, does, the, fog, raid, ...  \n",
       "2  [soo, i, had, been, eyeing, the, women, s, nik...  \n",
       "3  [i, remember, seeing, pictures, of, drake, wea...  \n",
       "4  [they, lasted, me, since, 2015, 5, years, serv...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_brands['total_tokens'] = cleaned_brands['title_tokens'] + cleaned_brands['text_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215778 words total, with a vocabulary size of 8410\n",
      "Max post length is 2645\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in cleaned_brands[\"total_tokens\"] for word in tokens]\n",
    "post_lengths = [len(tokens) for tokens in cleaned_brands[\"total_tokens\"]]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(f\"{len(all_words)} words total, with a vocabulary size of {len(VOCAB)}\")\n",
    "print(f\"Max post length is {max(post_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215778"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10)) \n",
    "plt.xlabel('Post length')\n",
    "plt.ylabel('Number of posts')\n",
    "plt.hist(post_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize self text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize title as well? or redundant of selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any image/video references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which columns to remove that have brand identifiers (brand name or product name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_brands['total_text'] = cleaned_brands['title'] + ' ' + cleaned_brands['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>are womens sizes the same as mens for nike m2k...</td>\n",
       "      <td>there is a particular colour of nike m2k train...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568401703</td>\n",
       "      <td>johnnyredneat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>[are, womens, sizes, the, same, as, mens, for,...</td>\n",
       "      <td>[there, is, a, particular, colour, of, nike, m...</td>\n",
       "      <td>[are, womens, sizes, the, same, as, mens, for,...</td>\n",
       "      <td>are womens sizes the same as mens for nike m2k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>laces</td>\n",
       "      <td>what kind of laces does the fog raid comes wit...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568406910</td>\n",
       "      <td>Hoxton_0451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>[laces]</td>\n",
       "      <td>[what, kind, of, laces, does, the, fog, raid, ...</td>\n",
       "      <td>[laces, what, kind, of, laces, does, the, fog,...</td>\n",
       "      <td>laces what kind of laces does the fog raid com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sizing question on buying men s for women  siz...</td>\n",
       "      <td>soo i had been eyeing the women s nike air max...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568443108</td>\n",
       "      <td>buzzbuzzbih</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[sizing, question, on, buying, men, s, for, wo...</td>\n",
       "      <td>[soo, i, had, been, eyeing, the, women, s, nik...</td>\n",
       "      <td>[sizing, question, on, buying, men, s, for, wo...</td>\n",
       "      <td>sizing question on buying men s for women  siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>trying to remember a hoodie or shirt drake wore</td>\n",
       "      <td>i remember seeing pictures of drake wearing a ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568486842</td>\n",
       "      <td>perpetualpies</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[trying, to, remember, a, hoodie, or, shirt, d...</td>\n",
       "      <td>[i, remember, seeing, pictures, of, drake, wea...</td>\n",
       "      <td>[trying, to, remember, a, hoodie, or, shirt, d...</td>\n",
       "      <td>trying to remember a hoodie or shirt drake wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thankyou to my nike tanjuns</td>\n",
       "      <td>they lasted me since 2015  5 years service a...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1568497739</td>\n",
       "      <td>adeptwarrior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>[thankyou, to, my, nike, tanjuns]</td>\n",
       "      <td>[they, lasted, me, since, 2015, 5, years, serv...</td>\n",
       "      <td>[thankyou, to, my, nike, tanjuns, they, lasted...</td>\n",
       "      <td>thankyou to my nike tanjuns   they lasted me s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  are womens sizes the same as mens for nike m2k...   \n",
       "1                                              laces   \n",
       "2  sizing question on buying men s for women  siz...   \n",
       "3    trying to remember a hoodie or shirt drake wore   \n",
       "4                        thankyou to my nike tanjuns   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  there is a particular colour of nike m2k train...      Nike   1568401703   \n",
       "1  what kind of laces does the fog raid comes wit...      Nike   1568406910   \n",
       "2  soo i had been eyeing the women s nike air max...      Nike   1568443108   \n",
       "3  i remember seeing pictures of drake wearing a ...      Nike   1568486842   \n",
       "4    they lasted me since 2015  5 years service a...      Nike   1568497739   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \\\n",
       "0  johnnyredneat             1      0     True  2019-09-13   \n",
       "1    Hoxton_0451             0      0     True  2019-09-13   \n",
       "2    buzzbuzzbih             3      0     True  2019-09-14   \n",
       "3  perpetualpies             3      0     True  2019-09-14   \n",
       "4   adeptwarrior             0      0     True  2019-09-14   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  [are, womens, sizes, the, same, as, mens, for,...   \n",
       "1                                            [laces]   \n",
       "2  [sizing, question, on, buying, men, s, for, wo...   \n",
       "3  [trying, to, remember, a, hoodie, or, shirt, d...   \n",
       "4                  [thankyou, to, my, nike, tanjuns]   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [there, is, a, particular, colour, of, nike, m...   \n",
       "1  [what, kind, of, laces, does, the, fog, raid, ...   \n",
       "2  [soo, i, had, been, eyeing, the, women, s, nik...   \n",
       "3  [i, remember, seeing, pictures, of, drake, wea...   \n",
       "4  [they, lasted, me, since, 2015, 5, years, serv...   \n",
       "\n",
       "                                        total_tokens  \\\n",
       "0  [are, womens, sizes, the, same, as, mens, for,...   \n",
       "1  [laces, what, kind, of, laces, does, the, fog,...   \n",
       "2  [sizing, question, on, buying, men, s, for, wo...   \n",
       "3  [trying, to, remember, a, hoodie, or, shirt, d...   \n",
       "4  [thankyou, to, my, nike, tanjuns, they, lasted...   \n",
       "\n",
       "                                          total_text  \n",
       "0  are womens sizes the same as mens for nike m2k...  \n",
       "1  laces what kind of laces does the fog raid com...  \n",
       "2  sizing question on buying men s for women  siz...  \n",
       "3  trying to remember a hoodie or shirt drake wor...  \n",
       "4  thankyou to my nike tanjuns   they lasted me s...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_brands.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_brands[['total_text']], \n",
    "                                                    cleaned_brands['subreddit'], \n",
    "                                                    test_size=.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the posts to a list of strings\n",
    "clean_train_posts = []\n",
    "clean_test_posts = []\n",
    "\n",
    "for train_post in X_train['total_text']:\n",
    "    clean_train_posts.append(train_post)\n",
    "    \n",
    "for test_post in X_test['total_text']:\n",
    "    clean_test_posts.append(test_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_train_posts\n",
    "X_test = clean_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate lists for creating a dataframe of models, scores later on\n",
    "models = []\n",
    "transformers = []\n",
    "stop_words = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9000759878419453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 1: cvec, logreg, no stop words\n",
    "pipe = Pipeline([('cvec', CountVectorizer()), ('lr', LogisticRegression())])\n",
    "\n",
    "pipe_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "               'cvec__min_df': [2, 3], \n",
    "               'cvec__max_df': [0.9, 0.95], \n",
    "               'cvec__ngram_range': [(1, 1), (1, 2)]}\n",
    "\n",
    "gs = GridSearchCV(pipe, pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Logistic_reg')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('none')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ['Logistic_reg']\n",
      "Transformer: ['cvec']\n",
      "Params: [{'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}]\n",
      "Stop words: ['none']\n",
      "Train score: [0.9912613981762918]\n",
      "Test scores: [0.9193262411347518]\n"
     ]
    }
   ],
   "source": [
    "# check lists\n",
    "print(f\"Model: {models}\")\n",
    "print(f\"Transformer: {transformers}\")\n",
    "print(f\"Params: {params}\")\n",
    "print(f\"Stop words: {stop_words}\")\n",
    "print(f\"Train score: {train_scores}\")\n",
    "print(f\"Test scores: {test_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894376899696048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'svc__C': 0.25,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 2: cvec, svc, no stop words\n",
    "pipe_2 = Pipeline([('cvec', CountVectorizer()), ('svc', SVC())])\n",
    "\n",
    "\n",
    "pipe_2_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'svc__C': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'svc__kernel': ['rbf', 'poly', 'linear'], \n",
    "                 'svc__gamma': ['scale']\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_2, pipe_2_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('SVC')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('none')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9008358662613982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'svc__C': 0.25,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 3: cvec, svc, English stop words\n",
    "pipe_3 = Pipeline([('cvec', CountVectorizer()), ('svc', SVC())])\n",
    "\n",
    "\n",
    "pipe_3_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': ['english'],\n",
    "                 'svc__C': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'svc__kernel': ['rbf', 'poly', 'linear'], \n",
    "                 'svc__gamma': ['scale']\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_3, pipe_3_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('SVC')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('English')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031914893617021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS'),\n",
       " 'svc__C': 1.0,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 4: cvec, svc, brand stop words\n",
    "pipe_4 = Pipeline([('cvec', CountVectorizer()), ('svc', SVC())])\n",
    "\n",
    "\n",
    "pipe_4_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': [('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')],\n",
    "                 'svc__C': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'svc__kernel': ['rbf', 'poly', 'linear'], \n",
    "                 'svc__gamma': ['scale']\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_4, pipe_4_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('SVC')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('Brand names')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.895516717325228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None,\n",
       " 'mnb__alpha': 0.75,\n",
       " 'mnb__fit_prior': False}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 5: cvec, naive bayes, none stop words\n",
    "pipe_5 = Pipeline([('cvec', CountVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_5_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': [None],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_5, pipe_5_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes (MNB)')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('none')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9057750759878419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'mnb__alpha': 0.25,\n",
       " 'mnb__fit_prior': False}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 6: cvec, naive bayes, English stop words\n",
    "pipe_6 = Pipeline([('cvec', CountVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_6_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': ['english'],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_6, pipe_6_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes (MNB)')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('English')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8104103343465046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS'),\n",
       " 'mnb__alpha': 0.25,\n",
       " 'mnb__fit_prior': False}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 7: cvec, naive bayes, brand stop words\n",
    "pipe_7 = Pipeline([('cvec', CountVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_7_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': [('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_7, pipe_7_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes (MNB)')\n",
    "\n",
    "transformers.append('cvec')\n",
    "\n",
    "stop_words.append('Brand names')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9110942249240122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1.0,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'rbf',\n",
       " 'tifdif__max_df': 0.9,\n",
       " 'tifdif__max_features': 1500,\n",
       " 'tifdif__min_df': 2,\n",
       " 'tifdif__ngram_range': (1, 2),\n",
       " 'tifdif__stop_words': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 8: tfidf, svc, no stop words\n",
    "pipe_8 = Pipeline([('tifdif', TfidfVectorizer()), ('svc', SVC())])\n",
    "\n",
    "pipe_8_params = {'tifdif__max_features': [500, 1000, 1500], \n",
    "                 'tifdif__min_df': [2, 3], \n",
    "                 'tifdif__max_df': [0.9, 0.95], \n",
    "                 'tifdif__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'tifdif__stop_words': [None],\n",
    "                 'svc__C': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'svc__kernel': ['rbf', 'poly', 'linear'], \n",
    "                 'svc__gamma': ['scale']\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_8, pipe_8_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('SVC')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('none')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918693009118541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1.0,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'rbf',\n",
       " 'tifdif__max_df': 0.9,\n",
       " 'tifdif__max_features': 1500,\n",
       " 'tifdif__min_df': 2,\n",
       " 'tifdif__ngram_range': (1, 2),\n",
       " 'tifdif__stop_words': 'english'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 9: tfidf, svc, English stop words\n",
    "pipe_9 = Pipeline([('tifdif', TfidfVectorizer()), ('svc', SVC())])\n",
    "\n",
    "pipe_9_params = {'tifdif__max_features': [500, 1000, 1500], \n",
    "                 'tifdif__min_df': [2, 3], \n",
    "                 'tifdif__max_df': [0.9, 0.95], \n",
    "                 'tifdif__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'tifdif__stop_words': ['english'],\n",
    "                 'svc__C': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'svc__kernel': ['rbf', 'poly', 'linear'], \n",
    "                 'svc__gamma': ['scale']\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_9, pipe_9_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('SVC')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('English')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8164893617021277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1.0,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'rbf',\n",
       " 'tifdif__max_df': 0.9,\n",
       " 'tifdif__max_features': 1500,\n",
       " 'tifdif__min_df': 3,\n",
       " 'tifdif__ngram_range': (1, 1),\n",
       " 'tifdif__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 10: tfidf, svc, brand stop words\n",
    "pipe_10 = Pipeline([('tifdif', TfidfVectorizer()), ('svc', SVC())])\n",
    "\n",
    "pipe_10_params = {'tifdif__max_features': [500, 1000, 1500], \n",
    "                 'tifdif__min_df': [2, 3], \n",
    "                 'tifdif__max_df': [0.9, 0.95], \n",
    "                 'tifdif__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'tifdif__stop_words': [('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')],\n",
    "                 'svc__C': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'svc__kernel': ['rbf', 'poly', 'linear'], \n",
    "                 'svc__gamma': ['scale']\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_10, pipe_10_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('SVC')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('Brand names')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863981762917933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 1.0,\n",
       " 'mnb__fit_prior': False,\n",
       " 'tifdif__max_df': 0.9,\n",
       " 'tifdif__max_features': 1500,\n",
       " 'tifdif__min_df': 2,\n",
       " 'tifdif__ngram_range': (1, 1),\n",
       " 'tifdif__stop_words': None}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 11: tfidf, naive bayes, no stop words\n",
    "pipe_11 = Pipeline([('tifdif', TfidfVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_11_params = {'tifdif__max_features': [500, 1000, 1500], \n",
    "                 'tifdif__min_df': [2, 3], \n",
    "                 'tifdif__max_df': [0.9, 0.95], \n",
    "                 'tifdif__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'tifdif__stop_words': [None],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_11, pipe_11_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes (MNB)')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('none')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947568389057751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 1.0,\n",
       " 'mnb__fit_prior': False,\n",
       " 'tifdif__max_df': 0.9,\n",
       " 'tifdif__max_features': 1500,\n",
       " 'tifdif__min_df': 2,\n",
       " 'tifdif__ngram_range': (1, 1),\n",
       " 'tifdif__stop_words': 'english'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 12: tfidf, naive bayes, English stop words\n",
    "pipe_12 = Pipeline([('tifdif', TfidfVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_12_params = {'tifdif__max_features': [500, 1000, 1500], \n",
    "                 'tifdif__min_df': [2, 3], \n",
    "                 'tifdif__max_df': [0.9, 0.95], \n",
    "                 'tifdif__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'tifdif__stop_words': ['english'],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_12, pipe_12_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes (MNB)')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('English')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8111702127659575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 0.25,\n",
       " 'mnb__fit_prior': False,\n",
       " 'tifdif__max_df': 0.9,\n",
       " 'tifdif__max_features': 1500,\n",
       " 'tifdif__min_df': 3,\n",
       " 'tifdif__ngram_range': (1, 1),\n",
       " 'tifdif__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 13: tfidf, naive bayes, brand stop words\n",
    "pipe_13 = Pipeline([('tifdif', TfidfVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_13_params = {'tifdif__max_features': [500, 1000, 1500], \n",
    "                 'tifdif__min_df': [2, 3], \n",
    "                 'tifdif__max_df': [0.9, 0.95], \n",
    "                 'tifdif__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'tifdif__stop_words': [('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_13, pipe_13_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes(MNB)')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('Brand names')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ['Logistic_reg', 'SVC', 'SVC', 'SVC', 'Naive Bayes (MNB)', 'Naive Bayes (MNB)', 'Naive Bayes (MNB)', 'SVC', 'SVC', 'SVC', 'Naive Bayes (MNB)', 'Naive Bayes (MNB)', 'Naive Bayes(MNB)']\n",
      "Transformer: ['cvec', 'cvec', 'cvec', 'cvec', 'cvec', 'cvec', 'cvec', 'tfidf', 'tfidf', 'tfidf', 'tfidf', 'tfidf', 'tfidf']\n",
      "Params: [{'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}, {'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'svc__C': 0.25, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}, {'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'svc__C': 0.25, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}, {'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS'), 'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}, {'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None, 'mnb__alpha': 0.75, 'mnb__fit_prior': False}, {'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'mnb__alpha': 0.25, 'mnb__fit_prior': False}, {'cvec__max_df': 0.9, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS'), 'mnb__alpha': 0.25, 'mnb__fit_prior': False}, {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__kernel': 'rbf', 'tifdif__max_df': 0.9, 'tifdif__max_features': 1500, 'tifdif__min_df': 2, 'tifdif__ngram_range': (1, 2), 'tifdif__stop_words': None}, {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__kernel': 'rbf', 'tifdif__max_df': 0.9, 'tifdif__max_features': 1500, 'tifdif__min_df': 2, 'tifdif__ngram_range': (1, 2), 'tifdif__stop_words': 'english'}, {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__kernel': 'rbf', 'tifdif__max_df': 0.9, 'tifdif__max_features': 1500, 'tifdif__min_df': 3, 'tifdif__ngram_range': (1, 1), 'tifdif__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')}, {'mnb__alpha': 1.0, 'mnb__fit_prior': False, 'tifdif__max_df': 0.9, 'tifdif__max_features': 1500, 'tifdif__min_df': 2, 'tifdif__ngram_range': (1, 1), 'tifdif__stop_words': None}, {'mnb__alpha': 1.0, 'mnb__fit_prior': False, 'tifdif__max_df': 0.9, 'tifdif__max_features': 1500, 'tifdif__min_df': 2, 'tifdif__ngram_range': (1, 1), 'tifdif__stop_words': 'english'}, {'mnb__alpha': 0.25, 'mnb__fit_prior': False, 'tifdif__max_df': 0.9, 'tifdif__max_features': 1500, 'tifdif__min_df': 3, 'tifdif__ngram_range': (1, 1), 'tifdif__stop_words': ('nike', 'Nike', 'adidas', 'Adidas', 'NIKE', 'ADIDAS')}]\n",
      "Stop words: ['none', 'none', 'English', 'Brand names', 'none', 'English', 'Brand names', 'none', 'English', 'Brand names', 'none', 'English', 'Brand names']\n",
      "Train score: [0.9912613981762918, 0.9867021276595744, 0.9821428571428571, 0.986322188449848, 0.9407294832826748, 0.9430091185410334, 0.8833586626139818, 0.9954407294832827, 0.993920972644377, 0.993161094224924, 0.9407294832826748, 0.9490881458966566, 0.9019756838905775]\n",
      "Test scores: [0.9193262411347518, 0.9095744680851063, 0.9078014184397163, 0.8368794326241135, 0.9024822695035462, 0.9113475177304965, 0.8173758865248227, 0.924645390070922, 0.9317375886524822, 0.8599290780141844, 0.8900709219858156, 0.9060283687943262, 0.8306737588652482]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: {models}\")\n",
    "print(f\"Transformer: {transformers}\")\n",
    "print(f\"Params: {params}\")\n",
    "print(f\"Stop words: {stop_words}\")\n",
    "print(f\"Train score: {train_scores}\")\n",
    "print(f\"Test scores: {test_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic_reg</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.991261</td>\n",
       "      <td>0.919326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.909574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.902482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.943009</td>\n",
       "      <td>0.911348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.817376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.995441</td>\n",
       "      <td>0.924645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.931738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>0.859929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.890071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.949088</td>\n",
       "      <td>0.906028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 0.25, 'mnb__fit_prior': False, ...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.901976</td>\n",
       "      <td>0.830674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Transformer  \\\n",
       "0        Logistic_reg        cvec   \n",
       "1                 SVC        cvec   \n",
       "2                 SVC        cvec   \n",
       "3                 SVC        cvec   \n",
       "4   Naive Bayes (MNB)        cvec   \n",
       "5   Naive Bayes (MNB)        cvec   \n",
       "6   Naive Bayes (MNB)        cvec   \n",
       "7                 SVC       tfidf   \n",
       "8                 SVC       tfidf   \n",
       "9                 SVC       tfidf   \n",
       "10  Naive Bayes (MNB)       tfidf   \n",
       "11  Naive Bayes (MNB)       tfidf   \n",
       "12   Naive Bayes(MNB)       tfidf   \n",
       "\n",
       "                                           Parameters   Stop Words  \\\n",
       "0   {'cvec__max_df': 0.9, 'cvec__max_features': 15...         none   \n",
       "1   {'cvec__max_df': 0.9, 'cvec__max_features': 15...         none   \n",
       "2   {'cvec__max_df': 0.9, 'cvec__max_features': 15...      English   \n",
       "3   {'cvec__max_df': 0.9, 'cvec__max_features': 15...  Brand names   \n",
       "4   {'cvec__max_df': 0.9, 'cvec__max_features': 15...         none   \n",
       "5   {'cvec__max_df': 0.9, 'cvec__max_features': 15...      English   \n",
       "6   {'cvec__max_df': 0.9, 'cvec__max_features': 15...  Brand names   \n",
       "7   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...         none   \n",
       "8   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...      English   \n",
       "9   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...  Brand names   \n",
       "10  {'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...         none   \n",
       "11  {'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...      English   \n",
       "12  {'mnb__alpha': 0.25, 'mnb__fit_prior': False, ...  Brand names   \n",
       "\n",
       "    Train Score  Test Score  \n",
       "0      0.991261    0.919326  \n",
       "1      0.986702    0.909574  \n",
       "2      0.982143    0.907801  \n",
       "3      0.986322    0.836879  \n",
       "4      0.940729    0.902482  \n",
       "5      0.943009    0.911348  \n",
       "6      0.883359    0.817376  \n",
       "7      0.995441    0.924645  \n",
       "8      0.993921    0.931738  \n",
       "9      0.993161    0.859929  \n",
       "10     0.940729    0.890071  \n",
       "11     0.949088    0.906028  \n",
       "12     0.901976    0.830674  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe of the different scores \n",
    "# scores_df = \n",
    "pd.DataFrame({\n",
    "    'Model': models, \n",
    "    'Transformer': transformers, \n",
    "    'Parameters': params, \n",
    "    'Stop Words': stop_words, \n",
    "    'Train Score': train_scores, \n",
    "    'Test Score': test_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>what s your guys s sizing on the airmax 97?</td>\n",
       "      <td>got them in my regular size, 11 5 recently   f...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1566211829</td>\n",
       "      <td>Gunboss01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>[what, s, your, guys, s, sizing, on, the, airm...</td>\n",
       "      <td>[got, them, in, my, regular, size, 11, 5, rece...</td>\n",
       "      <td>[what, s, your, guys, s, sizing, on, the, airm...</td>\n",
       "      <td>what s your guys s sizing on the airmax 97? go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>nike 270 react</td>\n",
       "      <td>does anyone have the nike 270 airmax and the 2...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1563966588</td>\n",
       "      <td>sfly2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>[nike, 270, react]</td>\n",
       "      <td>[does, anyone, have, the, nike, 270, airmax, a...</td>\n",
       "      <td>[nike, 270, react, does, anyone, have, the, ni...</td>\n",
       "      <td>nike 270 react does anyone have the nike 270 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>why is finishline so garbage</td>\n",
       "      <td>so i ordered airmax 270s few days ago and i go...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1564107096</td>\n",
       "      <td>Jackscott98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>[why, is, finishline, so, garbage]</td>\n",
       "      <td>[so, i, ordered, airmax, 270s, few, days, ago,...</td>\n",
       "      <td>[why, is, finishline, so, garbage, so, i, orde...</td>\n",
       "      <td>why is finishline so garbage so i ordered airm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>squeaky air max 270 help me please</td>\n",
       "      <td>i am having a very hard time understanding my ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1565628467</td>\n",
       "      <td>Airgiant15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>[squeaky, air, max, 270, help, me, please]</td>\n",
       "      <td>[i, am, having, a, very, hard, time, understan...</td>\n",
       "      <td>[squeaky, air, max, 270, help, me, please, i, ...</td>\n",
       "      <td>squeaky air max 270 help me please i am having...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>protection for white nike airmax 90</td>\n",
       "      <td>i just bought some white air max 90 essential,...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1561330812</td>\n",
       "      <td>Onlygoodvibesmmmkay</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-06-23</td>\n",
       "      <td>[protection, for, white, nike, airmax, 90]</td>\n",
       "      <td>[i, just, bought, some, white, air, max, 90, e...</td>\n",
       "      <td>[protection, for, white, nike, airmax, 90, i, ...</td>\n",
       "      <td>protection for white nike airmax 90 i just bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>is nikeairmaxca ca real?</td>\n",
       "      <td>there s a website up right now that s all  219...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1562026240</td>\n",
       "      <td>travworld</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>[is, nikeairmaxca, ca, real]</td>\n",
       "      <td>[there, s, a, website, up, right, now, that, s...</td>\n",
       "      <td>[is, nikeairmaxca, ca, real, there, s, a, webs...</td>\n",
       "      <td>is nikeairmaxca ca real? there s a website up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>airmax 720 question</td>\n",
       "      <td>so im thinking of buying the triple black 720s...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1559111564</td>\n",
       "      <td>Gabo1399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>[airmax, 720, question]</td>\n",
       "      <td>[so, im, thinking, of, buying, the, triple, bl...</td>\n",
       "      <td>[airmax, 720, question, so, im, thinking, of, ...</td>\n",
       "      <td>airmax 720 question so im thinking of buying t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>id on this airmax pls</td>\n",
       "      <td>amp  x200b</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1559149255</td>\n",
       "      <td>MauryAvero</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>[id, on, this, airmax, pls]</td>\n",
       "      <td>[amp, x200b]</td>\n",
       "      <td>[id, on, this, airmax, pls, amp, x200b]</td>\n",
       "      <td>id on this airmax pls  amp  x200b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>problems with my pair of airmax 270 s</td>\n",
       "      <td>i bought a pair of red oil airmax 270 s about ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1556057036</td>\n",
       "      <td>jackattack0627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>[problems, with, my, pair, of, airmax, 270, s]</td>\n",
       "      <td>[i, bought, a, pair, of, red, oil, airmax, 270...</td>\n",
       "      <td>[problems, with, my, pair, of, airmax, 270, s,...</td>\n",
       "      <td>problems with my pair of airmax 270 s i bought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>question about af1 sizing</td>\n",
       "      <td>i have been keen on looking into getting mysel...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1556774051</td>\n",
       "      <td>T_Eighteen</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>[question, about, af1, sizing]</td>\n",
       "      <td>[i, have, been, keen, on, looking, into, getti...</td>\n",
       "      <td>[question, about, af1, sizing, i, have, been, ...</td>\n",
       "      <td>question about af1 sizing i have been keen on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>air max 270 air bubbles</td>\n",
       "      <td>yo, i wanna ask you guys, is the rear  u  shap...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1557315173</td>\n",
       "      <td>MortalNocturne</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>[air, max, 270, air, bubbles]</td>\n",
       "      <td>[yo, i, wanna, ask, you, guys, is, the, rear, ...</td>\n",
       "      <td>[air, max, 270, air, bubbles, yo, i, wanna, as...</td>\n",
       "      <td>air max 270 air bubbles yo, i wanna ask you gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>nike airmax sequent 4 5 added height?</td>\n",
       "      <td>how much height do they add?</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1557524162</td>\n",
       "      <td>WertyX1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>[nike, airmax, sequent, 4, 5, added, height]</td>\n",
       "      <td>[how, much, height, do, they, add]</td>\n",
       "      <td>[nike, airmax, sequent, 4, 5, added, height, h...</td>\n",
       "      <td>nike airmax sequent 4 5 added height? how much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>761</td>\n",
       "      <td>really disappointed in the quality of the life...</td>\n",
       "      <td>been a lifelong nike customer and this past ye...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1552964772</td>\n",
       "      <td>RottenKodiak</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>[really, disappointed, in, the, quality, of, t...</td>\n",
       "      <td>[been, a, lifelong, nike, customer, and, this,...</td>\n",
       "      <td>[really, disappointed, in, the, quality, of, t...</td>\n",
       "      <td>really disappointed in the quality of the life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>nike shoe trade</td>\n",
       "      <td>guys, i need an opinion for this trade  what d...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1554377651</td>\n",
       "      <td>pauljmnz16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>[nike, shoe, trade]</td>\n",
       "      <td>[guys, i, need, an, opinion, for, this, trade,...</td>\n",
       "      <td>[nike, shoe, trade, guys, i, need, an, opinion...</td>\n",
       "      <td>nike shoe trade guys, i need an opinion for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842</td>\n",
       "      <td>air max bubble deflated</td>\n",
       "      <td>i have a pair of airmax that keep squeaking  i...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1554687393</td>\n",
       "      <td>jj71787</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>[air, max, bubble, deflated]</td>\n",
       "      <td>[i, have, a, pair, of, airmax, that, keep, squ...</td>\n",
       "      <td>[air, max, bubble, deflated, i, have, a, pair,...</td>\n",
       "      <td>air max bubble deflated i have a pair of airma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>air max 97 sizing</td>\n",
       "      <td>how is the size on this? i only bought yeezys ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1555194172</td>\n",
       "      <td>ELOGRIN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>[air, max, 97, sizing]</td>\n",
       "      <td>[how, is, the, size, on, this, i, only, bought...</td>\n",
       "      <td>[air, max, 97, sizing, how, is, the, size, on,...</td>\n",
       "      <td>air max 97 sizing  how is the size on this? i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>shoes similar to</td>\n",
       "      <td>looking for shoes similar to fit and look of t...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1547672914</td>\n",
       "      <td>zack7891</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>[shoes, similar, to]</td>\n",
       "      <td>[looking, for, shoes, similar, to, fit, and, l...</td>\n",
       "      <td>[shoes, similar, to, looking, for, shoes, simi...</td>\n",
       "      <td>shoes similar to     looking for shoes similar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>air max 270 sizing</td>\n",
       "      <td>i just purchased the nike airmax 270 s in a si...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1548610439</td>\n",
       "      <td>gabbidib</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>[air, max, 270, sizing]</td>\n",
       "      <td>[i, just, purchased, the, nike, airmax, 270, s...</td>\n",
       "      <td>[air, max, 270, sizing, i, just, purchased, th...</td>\n",
       "      <td>air max 270 sizing i just purchased the nike a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1123</td>\n",
       "      <td>new runners cutting the back of my ankle</td>\n",
       "      <td>got new runners (nike airmax 90) and, as the t...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1545833049</td>\n",
       "      <td>idontlikehats</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>[new, runners, cutting, the, back, of, my, ankle]</td>\n",
       "      <td>[got, new, runners, nike, airmax, 90, and, as,...</td>\n",
       "      <td>[new, runners, cutting, the, back, of, my, ank...</td>\n",
       "      <td>new runners cutting the back of my ankle  got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1165</td>\n",
       "      <td>black nike joggers with a yellow gold tick?</td>\n",
       "      <td>does anyone know if there exists a nike tracks...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1547229771</td>\n",
       "      <td>TroubledYout</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>[black, nike, joggers, with, a, yellow, gold, ...</td>\n",
       "      <td>[does, anyone, know, if, there, exists, a, nik...</td>\n",
       "      <td>[black, nike, joggers, with, a, yellow, gold, ...</td>\n",
       "      <td>black nike joggers with a yellow gold tick? do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1191</td>\n",
       "      <td>airmax 270</td>\n",
       "      <td>quick question about air max 270 and would lov...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1542999612</td>\n",
       "      <td>Monsieurcrepe</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>[airmax, 270]</td>\n",
       "      <td>[quick, question, about, air, max, 270, and, w...</td>\n",
       "      <td>[airmax, 270, quick, question, about, air, max...</td>\n",
       "      <td>airmax 270 quick question about air max 270 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1429</td>\n",
       "      <td>just got a pair of airmax 270 s, tongue folds ...</td>\n",
       "      <td>size is perfect but it seems i have a skinny f...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1536374879</td>\n",
       "      <td>MlCKJAGGER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>[just, got, a, pair, of, airmax, 270, s, tongu...</td>\n",
       "      <td>[size, is, perfect, but, it, seems, i, have, a...</td>\n",
       "      <td>[just, got, a, pair, of, airmax, 270, s, tongu...</td>\n",
       "      <td>just got a pair of airmax 270 s, tongue folds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>adidas is pissing me off somethimes</td>\n",
       "      <td>the first thing  i want to start by telling yo...</td>\n",
       "      <td>adidas</td>\n",
       "      <td>1538399870</td>\n",
       "      <td>FantasticRob65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>[adidas, is, pissing, me, off, somethimes]</td>\n",
       "      <td>[the, first, thing, i, want, to, start, by, te...</td>\n",
       "      <td>[adidas, is, pissing, me, off, somethimes, the...</td>\n",
       "      <td>adidas is pissing me off somethimes  the first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3913</td>\n",
       "      <td>what s your guys s sizing on the airmax 97?</td>\n",
       "      <td>got them in my regular size, 11 5 recently   f...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1566211829</td>\n",
       "      <td>Gunboss01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>[what, s, your, guys, s, sizing, on, the, airm...</td>\n",
       "      <td>[got, them, in, my, regular, size, 11, 5, rece...</td>\n",
       "      <td>[what, s, your, guys, s, sizing, on, the, airm...</td>\n",
       "      <td>what s your guys s sizing on the airmax 97? go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3956</td>\n",
       "      <td>squeaky air max 270 help me please</td>\n",
       "      <td>i am having a very hard time understanding my ...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1565628467</td>\n",
       "      <td>Airgiant15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>[squeaky, air, max, 270, help, me, please]</td>\n",
       "      <td>[i, am, having, a, very, hard, time, understan...</td>\n",
       "      <td>[squeaky, air, max, 270, help, me, please, i, ...</td>\n",
       "      <td>squeaky air max 270 help me please i am having...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4051</td>\n",
       "      <td>why is finishline so garbage</td>\n",
       "      <td>so i ordered airmax 270s few days ago and i go...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1564107096</td>\n",
       "      <td>Jackscott98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>[why, is, finishline, so, garbage]</td>\n",
       "      <td>[so, i, ordered, airmax, 270s, few, days, ago,...</td>\n",
       "      <td>[why, is, finishline, so, garbage, so, i, orde...</td>\n",
       "      <td>why is finishline so garbage so i ordered airm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4064</td>\n",
       "      <td>nike 270 react</td>\n",
       "      <td>does anyone have the nike 270 airmax and the 2...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1563966588</td>\n",
       "      <td>sfly2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>[nike, 270, react]</td>\n",
       "      <td>[does, anyone, have, the, nike, 270, airmax, a...</td>\n",
       "      <td>[nike, 270, react, does, anyone, have, the, ni...</td>\n",
       "      <td>nike 270 react does anyone have the nike 270 a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "176         what s your guys s sizing on the airmax 97?   \n",
       "319                                      nike 270 react   \n",
       "327                        why is finishline so garbage   \n",
       "424                  squeaky air max 270 help me please   \n",
       "454                 protection for white nike airmax 90   \n",
       "484                            is nikeairmaxca ca real?   \n",
       "585                                 airmax 720 question   \n",
       "588                               id on this airmax pls   \n",
       "674               problems with my pair of airmax 270 s   \n",
       "698                           question about af1 sizing   \n",
       "725                             air max 270 air bubbles   \n",
       "736               nike airmax sequent 4 5 added height?   \n",
       "761   really disappointed in the quality of the life...   \n",
       "834                                     nike shoe trade   \n",
       "842                             air max bubble deflated   \n",
       "874                                  air max 97 sizing    \n",
       "1001                               shoes similar to       \n",
       "1030                                 air max 270 sizing   \n",
       "1123          new runners cutting the back of my ankle    \n",
       "1165        black nike joggers with a yellow gold tick?   \n",
       "1191                                         airmax 270   \n",
       "1429  just got a pair of airmax 270 s, tongue folds ...   \n",
       "2890               adidas is pissing me off somethimes    \n",
       "3913        what s your guys s sizing on the airmax 97?   \n",
       "3956                 squeaky air max 270 help me please   \n",
       "4051                       why is finishline so garbage   \n",
       "4064                                     nike 270 react   \n",
       "\n",
       "                                               selftext subreddit  \\\n",
       "176   got them in my regular size, 11 5 recently   f...      Nike   \n",
       "319   does anyone have the nike 270 airmax and the 2...      Nike   \n",
       "327   so i ordered airmax 270s few days ago and i go...      Nike   \n",
       "424   i am having a very hard time understanding my ...      Nike   \n",
       "454   i just bought some white air max 90 essential,...      Nike   \n",
       "484   there s a website up right now that s all  219...      Nike   \n",
       "585   so im thinking of buying the triple black 720s...      Nike   \n",
       "588                                       amp  x200b         Nike   \n",
       "674   i bought a pair of red oil airmax 270 s about ...      Nike   \n",
       "698   i have been keen on looking into getting mysel...      Nike   \n",
       "725   yo, i wanna ask you guys, is the rear  u  shap...      Nike   \n",
       "736                        how much height do they add?      Nike   \n",
       "761   been a lifelong nike customer and this past ye...      Nike   \n",
       "834   guys, i need an opinion for this trade  what d...      Nike   \n",
       "842   i have a pair of airmax that keep squeaking  i...      Nike   \n",
       "874   how is the size on this? i only bought yeezys ...      Nike   \n",
       "1001  looking for shoes similar to fit and look of t...      Nike   \n",
       "1030  i just purchased the nike airmax 270 s in a si...      Nike   \n",
       "1123  got new runners (nike airmax 90) and, as the t...      Nike   \n",
       "1165  does anyone know if there exists a nike tracks...      Nike   \n",
       "1191  quick question about air max 270 and would lov...      Nike   \n",
       "1429  size is perfect but it seems i have a skinny f...      Nike   \n",
       "2890  the first thing  i want to start by telling yo...    adidas   \n",
       "3913  got them in my regular size, 11 5 recently   f...      Nike   \n",
       "3956  i am having a very hard time understanding my ...      Nike   \n",
       "4051  so i ordered airmax 270s few days ago and i go...      Nike   \n",
       "4064  does anyone have the nike 270 airmax and the 2...      Nike   \n",
       "\n",
       "      created_utc               author  num_comments  score  is_self  \\\n",
       "176    1566211829            Gunboss01             1      1     True   \n",
       "319    1563966588             sfly2014             3      2     True   \n",
       "327    1564107096          Jackscott98             1      1     True   \n",
       "424    1565628467           Airgiant15            10      1     True   \n",
       "454    1561330812  Onlygoodvibesmmmkay             1      1     True   \n",
       "484    1562026240            travworld             2      0     True   \n",
       "585    1559111564             Gabo1399             1      1     True   \n",
       "588    1559149255           MauryAvero             0      1     True   \n",
       "674    1556057036       jackattack0627             1      1     True   \n",
       "698    1556774051           T_Eighteen             5      1     True   \n",
       "725    1557315173       MortalNocturne            12      1     True   \n",
       "736    1557524162              WertyX1             0      6     True   \n",
       "761    1552964772         RottenKodiak             0      2     True   \n",
       "834    1554377651           pauljmnz16             0      0     True   \n",
       "842    1554687393              jj71787             2      1     True   \n",
       "874    1555194172              ELOGRIN             0      1     True   \n",
       "1001   1547672914             zack7891             1      1     True   \n",
       "1030   1548610439             gabbidib             0      1     True   \n",
       "1123   1545833049        idontlikehats             2      1     True   \n",
       "1165   1547229771         TroubledYout             0      1     True   \n",
       "1191   1542999612        Monsieurcrepe             6      1     True   \n",
       "1429   1536374879           MlCKJAGGER             0      1     True   \n",
       "2890   1538399870       FantasticRob65             1      1     True   \n",
       "3913   1566211829            Gunboss01             1      1     True   \n",
       "3956   1565628467           Airgiant15            10      1     True   \n",
       "4051   1564107096          Jackscott98             1      1     True   \n",
       "4064   1563966588             sfly2014             3      2     True   \n",
       "\n",
       "       timestamp                                       title_tokens  \\\n",
       "176   2019-08-19  [what, s, your, guys, s, sizing, on, the, airm...   \n",
       "319   2019-07-24                                 [nike, 270, react]   \n",
       "327   2019-07-25                 [why, is, finishline, so, garbage]   \n",
       "424   2019-08-12         [squeaky, air, max, 270, help, me, please]   \n",
       "454   2019-06-23         [protection, for, white, nike, airmax, 90]   \n",
       "484   2019-07-01                       [is, nikeairmaxca, ca, real]   \n",
       "585   2019-05-29                            [airmax, 720, question]   \n",
       "588   2019-05-29                        [id, on, this, airmax, pls]   \n",
       "674   2019-04-23     [problems, with, my, pair, of, airmax, 270, s]   \n",
       "698   2019-05-02                     [question, about, af1, sizing]   \n",
       "725   2019-05-08                      [air, max, 270, air, bubbles]   \n",
       "736   2019-05-10       [nike, airmax, sequent, 4, 5, added, height]   \n",
       "761   2019-03-18  [really, disappointed, in, the, quality, of, t...   \n",
       "834   2019-04-04                                [nike, shoe, trade]   \n",
       "842   2019-04-07                       [air, max, bubble, deflated]   \n",
       "874   2019-04-13                             [air, max, 97, sizing]   \n",
       "1001  2019-01-16                               [shoes, similar, to]   \n",
       "1030  2019-01-27                            [air, max, 270, sizing]   \n",
       "1123  2018-12-26  [new, runners, cutting, the, back, of, my, ankle]   \n",
       "1165  2019-01-11  [black, nike, joggers, with, a, yellow, gold, ...   \n",
       "1191  2018-11-23                                      [airmax, 270]   \n",
       "1429  2018-09-07  [just, got, a, pair, of, airmax, 270, s, tongu...   \n",
       "2890  2018-10-01         [adidas, is, pissing, me, off, somethimes]   \n",
       "3913  2019-08-19  [what, s, your, guys, s, sizing, on, the, airm...   \n",
       "3956  2019-08-12         [squeaky, air, max, 270, help, me, please]   \n",
       "4051  2019-07-25                 [why, is, finishline, so, garbage]   \n",
       "4064  2019-07-24                                 [nike, 270, react]   \n",
       "\n",
       "                                            text_tokens  \\\n",
       "176   [got, them, in, my, regular, size, 11, 5, rece...   \n",
       "319   [does, anyone, have, the, nike, 270, airmax, a...   \n",
       "327   [so, i, ordered, airmax, 270s, few, days, ago,...   \n",
       "424   [i, am, having, a, very, hard, time, understan...   \n",
       "454   [i, just, bought, some, white, air, max, 90, e...   \n",
       "484   [there, s, a, website, up, right, now, that, s...   \n",
       "585   [so, im, thinking, of, buying, the, triple, bl...   \n",
       "588                                        [amp, x200b]   \n",
       "674   [i, bought, a, pair, of, red, oil, airmax, 270...   \n",
       "698   [i, have, been, keen, on, looking, into, getti...   \n",
       "725   [yo, i, wanna, ask, you, guys, is, the, rear, ...   \n",
       "736                  [how, much, height, do, they, add]   \n",
       "761   [been, a, lifelong, nike, customer, and, this,...   \n",
       "834   [guys, i, need, an, opinion, for, this, trade,...   \n",
       "842   [i, have, a, pair, of, airmax, that, keep, squ...   \n",
       "874   [how, is, the, size, on, this, i, only, bought...   \n",
       "1001  [looking, for, shoes, similar, to, fit, and, l...   \n",
       "1030  [i, just, purchased, the, nike, airmax, 270, s...   \n",
       "1123  [got, new, runners, nike, airmax, 90, and, as,...   \n",
       "1165  [does, anyone, know, if, there, exists, a, nik...   \n",
       "1191  [quick, question, about, air, max, 270, and, w...   \n",
       "1429  [size, is, perfect, but, it, seems, i, have, a...   \n",
       "2890  [the, first, thing, i, want, to, start, by, te...   \n",
       "3913  [got, them, in, my, regular, size, 11, 5, rece...   \n",
       "3956  [i, am, having, a, very, hard, time, understan...   \n",
       "4051  [so, i, ordered, airmax, 270s, few, days, ago,...   \n",
       "4064  [does, anyone, have, the, nike, 270, airmax, a...   \n",
       "\n",
       "                                           total_tokens  \\\n",
       "176   [what, s, your, guys, s, sizing, on, the, airm...   \n",
       "319   [nike, 270, react, does, anyone, have, the, ni...   \n",
       "327   [why, is, finishline, so, garbage, so, i, orde...   \n",
       "424   [squeaky, air, max, 270, help, me, please, i, ...   \n",
       "454   [protection, for, white, nike, airmax, 90, i, ...   \n",
       "484   [is, nikeairmaxca, ca, real, there, s, a, webs...   \n",
       "585   [airmax, 720, question, so, im, thinking, of, ...   \n",
       "588             [id, on, this, airmax, pls, amp, x200b]   \n",
       "674   [problems, with, my, pair, of, airmax, 270, s,...   \n",
       "698   [question, about, af1, sizing, i, have, been, ...   \n",
       "725   [air, max, 270, air, bubbles, yo, i, wanna, as...   \n",
       "736   [nike, airmax, sequent, 4, 5, added, height, h...   \n",
       "761   [really, disappointed, in, the, quality, of, t...   \n",
       "834   [nike, shoe, trade, guys, i, need, an, opinion...   \n",
       "842   [air, max, bubble, deflated, i, have, a, pair,...   \n",
       "874   [air, max, 97, sizing, how, is, the, size, on,...   \n",
       "1001  [shoes, similar, to, looking, for, shoes, simi...   \n",
       "1030  [air, max, 270, sizing, i, just, purchased, th...   \n",
       "1123  [new, runners, cutting, the, back, of, my, ank...   \n",
       "1165  [black, nike, joggers, with, a, yellow, gold, ...   \n",
       "1191  [airmax, 270, quick, question, about, air, max...   \n",
       "1429  [just, got, a, pair, of, airmax, 270, s, tongu...   \n",
       "2890  [adidas, is, pissing, me, off, somethimes, the...   \n",
       "3913  [what, s, your, guys, s, sizing, on, the, airm...   \n",
       "3956  [squeaky, air, max, 270, help, me, please, i, ...   \n",
       "4051  [why, is, finishline, so, garbage, so, i, orde...   \n",
       "4064  [nike, 270, react, does, anyone, have, the, ni...   \n",
       "\n",
       "                                             total_text  \n",
       "176   what s your guys s sizing on the airmax 97? go...  \n",
       "319   nike 270 react does anyone have the nike 270 a...  \n",
       "327   why is finishline so garbage so i ordered airm...  \n",
       "424   squeaky air max 270 help me please i am having...  \n",
       "454   protection for white nike airmax 90 i just bou...  \n",
       "484   is nikeairmaxca ca real? there s a website up ...  \n",
       "585   airmax 720 question so im thinking of buying t...  \n",
       "588                id on this airmax pls  amp  x200b     \n",
       "674   problems with my pair of airmax 270 s i bought...  \n",
       "698   question about af1 sizing i have been keen on ...  \n",
       "725   air max 270 air bubbles yo, i wanna ask you gu...  \n",
       "736   nike airmax sequent 4 5 added height? how much...  \n",
       "761   really disappointed in the quality of the life...  \n",
       "834   nike shoe trade guys, i need an opinion for th...  \n",
       "842   air max bubble deflated i have a pair of airma...  \n",
       "874   air max 97 sizing  how is the size on this? i ...  \n",
       "1001  shoes similar to     looking for shoes similar...  \n",
       "1030  air max 270 sizing i just purchased the nike a...  \n",
       "1123  new runners cutting the back of my ankle  got ...  \n",
       "1165  black nike joggers with a yellow gold tick? do...  \n",
       "1191  airmax 270 quick question about air max 270 an...  \n",
       "1429  just got a pair of airmax 270 s, tongue folds ...  \n",
       "2890  adidas is pissing me off somethimes  the first...  \n",
       "3913  what s your guys s sizing on the airmax 97? go...  \n",
       "3956  squeaky air max 270 help me please i am having...  \n",
       "4051  why is finishline so garbage so i ordered airm...  \n",
       "4064  nike 270 react does anyone have the nike 270 a...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how often populare product names occur\n",
    "cleaned_brands[cleaned_brands['total_text'].str.contains('airmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 13)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_brands[cleaned_brands['total_text'].str.contains('fly knit')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8932370820668692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': ('air max',\n",
       "  'airmax',\n",
       "  'ultra boost',\n",
       "  'ultraboost',\n",
       "  'superstar',\n",
       "  'flyknit'),\n",
       " 'mnb__alpha': 0.5,\n",
       " 'mnb__fit_prior': False}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 14: tfidf, naive bayes, product stop words\n",
    "pipe_14 = Pipeline([('cvec', CountVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_14_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': [('air max', 'airmax', 'ultra boost', 'ultraboost', 'superstar', 'flyknit')],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_14, pipe_14_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes(MNB)')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('Product names')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic_reg</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.991261</td>\n",
       "      <td>0.919326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.909574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.902482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.943009</td>\n",
       "      <td>0.911348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.817376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.995441</td>\n",
       "      <td>0.924645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.931738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>0.859929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.890071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.949088</td>\n",
       "      <td>0.906028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 0.25, 'mnb__fit_prior': False, ...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.901976</td>\n",
       "      <td>0.830674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product names</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.900709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product and Brand names</td>\n",
       "      <td>0.881839</td>\n",
       "      <td>0.811170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product names</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>0.897163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Transformer  \\\n",
       "0        Logistic_reg        cvec   \n",
       "1                 SVC        cvec   \n",
       "2                 SVC        cvec   \n",
       "3                 SVC        cvec   \n",
       "4   Naive Bayes (MNB)        cvec   \n",
       "5   Naive Bayes (MNB)        cvec   \n",
       "6   Naive Bayes (MNB)        cvec   \n",
       "7                 SVC       tfidf   \n",
       "8                 SVC       tfidf   \n",
       "9                 SVC       tfidf   \n",
       "10  Naive Bayes (MNB)       tfidf   \n",
       "11  Naive Bayes (MNB)       tfidf   \n",
       "12   Naive Bayes(MNB)       tfidf   \n",
       "13   Naive Bayes(MNB)       tfidf   \n",
       "14   Naive Bayes(MNB)       tfidf   \n",
       "15   Naive Bayes(MNB)       tfidf   \n",
       "\n",
       "                                           Parameters  \\\n",
       "0   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "1   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "2   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "3   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "4   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "5   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "6   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "7   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...   \n",
       "8   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...   \n",
       "9   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...   \n",
       "10  {'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...   \n",
       "11  {'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...   \n",
       "12  {'mnb__alpha': 0.25, 'mnb__fit_prior': False, ...   \n",
       "13  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "14  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "15  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "\n",
       "                 Stop Words  Train Score  Test Score  \n",
       "0                      none     0.991261    0.919326  \n",
       "1                      none     0.986702    0.909574  \n",
       "2                   English     0.982143    0.907801  \n",
       "3               Brand names     0.986322    0.836879  \n",
       "4                      none     0.940729    0.902482  \n",
       "5                   English     0.943009    0.911348  \n",
       "6               Brand names     0.883359    0.817376  \n",
       "7                      none     0.995441    0.924645  \n",
       "8                   English     0.993921    0.931738  \n",
       "9               Brand names     0.993161    0.859929  \n",
       "10                     none     0.940729    0.890071  \n",
       "11                  English     0.949088    0.906028  \n",
       "12              Brand names     0.901976    0.830674  \n",
       "13            Product names     0.940729    0.900709  \n",
       "14  Product and Brand names     0.881839    0.811170  \n",
       "15            Product names     0.939210    0.897163  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores_df = \n",
    "pd.DataFrame({\n",
    "    'Model': models, \n",
    "    'Transformer': transformers, \n",
    "    'Parameters': params, \n",
    "    'Stop Words': stop_words, \n",
    "    'Train Score': train_scores, \n",
    "    'Test Score': test_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8012917933130699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'boost', 'max', 'ultra'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': ('air max',\n",
       "  'airmax',\n",
       "  'ultra boost',\n",
       "  'ultraboost',\n",
       "  'superstar',\n",
       "  'flyknit',\n",
       "  'adidas',\n",
       "  'nike'),\n",
       " 'mnb__alpha': 0.25,\n",
       " 'mnb__fit_prior': True}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 15: tfidf, naive bayes, product and brand stop words\n",
    "pipe_15 = Pipeline([('cvec', CountVectorizer()), ('mnb', MultinomialNB())])\n",
    "\n",
    "pipe_15_params = {'cvec__max_features': [500, 1000, 1500], \n",
    "                 'cvec__min_df': [2, 3], \n",
    "                 'cvec__max_df': [0.9, 0.95], \n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "                 'cvec__stop_words': [('air max', 'airmax', 'ultra boost', 'ultraboost', 'superstar', 'flyknit', 'adidas', 'nike')],\n",
    "                 'mnb__alpha': [1.0, 0.75, 0.5, 0.25], \n",
    "                 'mnb__fit_prior': [True, False]\n",
    "                }\n",
    "\n",
    "gs = GridSearchCV(pipe_15, pipe_15_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_\n",
    "\n",
    "pipe_train = gs_model.score(X_train, y_train)\n",
    "train_scores.append(pipe_train)\n",
    "\n",
    "pipe_test = gs_model.score(X_test, y_test)\n",
    "test_scores.append(pipe_test)\n",
    "\n",
    "models.append('Naive Bayes(MNB)')\n",
    "\n",
    "transformers.append('tfidf')\n",
    "\n",
    "stop_words.append('Product and Brand names')\n",
    "\n",
    "params.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame({\n",
    "    'Model': models, \n",
    "    'Transformer': transformers, \n",
    "    'Parameters': params, \n",
    "    'Stop Words': stop_words, \n",
    "    'Train Score': train_scores, \n",
    "    'Test Score': test_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic_reg</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.991261</td>\n",
       "      <td>0.919326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.909574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.902482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.943009</td>\n",
       "      <td>0.911348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.817376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.995441</td>\n",
       "      <td>0.924645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.931738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>0.859929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.890071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...</td>\n",
       "      <td>English</td>\n",
       "      <td>0.949088</td>\n",
       "      <td>0.906028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'mnb__alpha': 0.25, 'mnb__fit_prior': False, ...</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.901976</td>\n",
       "      <td>0.830674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product names</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.900709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product and Brand names</td>\n",
       "      <td>0.881839</td>\n",
       "      <td>0.811170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product names</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>0.897163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 15...</td>\n",
       "      <td>Product and Brand names</td>\n",
       "      <td>0.878040</td>\n",
       "      <td>0.806738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Transformer  \\\n",
       "0        Logistic_reg        cvec   \n",
       "1                 SVC        cvec   \n",
       "2                 SVC        cvec   \n",
       "3                 SVC        cvec   \n",
       "4   Naive Bayes (MNB)        cvec   \n",
       "5   Naive Bayes (MNB)        cvec   \n",
       "6   Naive Bayes (MNB)        cvec   \n",
       "7                 SVC       tfidf   \n",
       "8                 SVC       tfidf   \n",
       "9                 SVC       tfidf   \n",
       "10  Naive Bayes (MNB)       tfidf   \n",
       "11  Naive Bayes (MNB)       tfidf   \n",
       "12   Naive Bayes(MNB)       tfidf   \n",
       "13   Naive Bayes(MNB)       tfidf   \n",
       "14   Naive Bayes(MNB)       tfidf   \n",
       "15   Naive Bayes(MNB)       tfidf   \n",
       "16   Naive Bayes(MNB)       tfidf   \n",
       "\n",
       "                                           Parameters  \\\n",
       "0   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "1   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "2   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "3   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "4   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "5   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "6   {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "7   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...   \n",
       "8   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...   \n",
       "9   {'svc__C': 1.0, 'svc__gamma': 'scale', 'svc__k...   \n",
       "10  {'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...   \n",
       "11  {'mnb__alpha': 1.0, 'mnb__fit_prior': False, '...   \n",
       "12  {'mnb__alpha': 0.25, 'mnb__fit_prior': False, ...   \n",
       "13  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "14  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "15  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "16  {'cvec__max_df': 0.9, 'cvec__max_features': 15...   \n",
       "\n",
       "                 Stop Words  Train Score  Test Score  \n",
       "0                      none     0.991261    0.919326  \n",
       "1                      none     0.986702    0.909574  \n",
       "2                   English     0.982143    0.907801  \n",
       "3               Brand names     0.986322    0.836879  \n",
       "4                      none     0.940729    0.902482  \n",
       "5                   English     0.943009    0.911348  \n",
       "6               Brand names     0.883359    0.817376  \n",
       "7                      none     0.995441    0.924645  \n",
       "8                   English     0.993921    0.931738  \n",
       "9               Brand names     0.993161    0.859929  \n",
       "10                     none     0.940729    0.890071  \n",
       "11                  English     0.949088    0.906028  \n",
       "12              Brand names     0.901976    0.830674  \n",
       "13            Product names     0.940729    0.900709  \n",
       "14  Product and Brand names     0.881839    0.811170  \n",
       "15            Product names     0.939210    0.897163  \n",
       "16  Product and Brand names     0.878040    0.806738  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.drop(scores_df.index[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.drop(scores_df.index[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1 = scores_df.drop('Parameters', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>none</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.909574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>English</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVC</td>\n",
       "      <td>cvec</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.902482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>English</td>\n",
       "      <td>0.943009</td>\n",
       "      <td>0.911348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>cvec</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.817376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>none</td>\n",
       "      <td>0.995441</td>\n",
       "      <td>0.924645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>English</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.931738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SVC</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>0.859929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>none</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.890071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Naive Bayes (MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>English</td>\n",
       "      <td>0.949088</td>\n",
       "      <td>0.906028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>Brand names</td>\n",
       "      <td>0.901976</td>\n",
       "      <td>0.830674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>Product names</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>0.897163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Naive Bayes(MNB)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>Product and Brand names</td>\n",
       "      <td>0.878040</td>\n",
       "      <td>0.806738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Transformer               Stop Words  Train Score  \\\n",
       "1                 SVC        cvec                     none     0.986702   \n",
       "2                 SVC        cvec                  English     0.982143   \n",
       "3                 SVC        cvec              Brand names     0.986322   \n",
       "4   Naive Bayes (MNB)        cvec                     none     0.940729   \n",
       "5   Naive Bayes (MNB)        cvec                  English     0.943009   \n",
       "6   Naive Bayes (MNB)        cvec              Brand names     0.883359   \n",
       "7                 SVC       tfidf                     none     0.995441   \n",
       "8                 SVC       tfidf                  English     0.993921   \n",
       "9                 SVC       tfidf              Brand names     0.993161   \n",
       "10  Naive Bayes (MNB)       tfidf                     none     0.940729   \n",
       "11  Naive Bayes (MNB)       tfidf                  English     0.949088   \n",
       "12   Naive Bayes(MNB)       tfidf              Brand names     0.901976   \n",
       "15   Naive Bayes(MNB)       tfidf            Product names     0.939210   \n",
       "16   Naive Bayes(MNB)       tfidf  Product and Brand names     0.878040   \n",
       "\n",
       "    Test Score  \n",
       "1     0.909574  \n",
       "2     0.907801  \n",
       "3     0.836879  \n",
       "4     0.902482  \n",
       "5     0.911348  \n",
       "6     0.817376  \n",
       "7     0.924645  \n",
       "8     0.931738  \n",
       "9     0.859929  \n",
       "10    0.890071  \n",
       "11    0.906028  \n",
       "12    0.830674  \n",
       "15    0.897163  \n",
       "16    0.806738  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_1.drop(scores_1.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied different transformers (Count Vectorizer and TFIDF Vectorizer) to different models (Logistic Regression, Support Vector Classifier, and Naive Bayes Multinomial), and incorporated different stop word exclusions (none, English, brand names, product names). Overall, I found the highest test accuracy scores and least amount of overfitting in the Naive Bayes model using either transformer and excluding either English or product names as stopwords. \n",
    "\n",
    "Removing brand names was not enough to prevent overfitting, however removing product names saw better improvement on the overfitting because they occurred more often. When people are talking about either brand online, they are often referring to a specific product from that brand. When using a popular product name, the brand is often left out because it is intuitively implied by using the product name. This is particularly the case in this instance of Nike and Adidas, which both have excellent brand recognition. \n",
    "\n",
    "As next steps and further iterations on this project and model, I would get more historical data. The data I included ranged from December 2018 to October 2019. I think it would add more value to include more historical data, which would ultimately make my model stronger and potentially better at predicting new posts. \n",
    "\n",
    "Furthermore, the topics of conversation around these products on reddit were largely centered around selling/buying shoes, customer service related questions, searching for promo codes, etc. While my problem statement and initial questions about the data centered around relating the conversations taking place online to the marketing campaigns of each respective company, I learned throughout my EDA process that these perhaps were not the right questions for this particular set of data. The reddit posts are more \"business as usual\" than \"on brand\" conversations. In future iterations or deveopment of my model, I would also compare these posts to each respective brand's marketing campaigns. I think this could introduce more of a real-world business application for this project. If a marketing department can understand if the online reddit community is talking about their products in the way they intended (i.e. using the messaging they have used in their campaigns), they can use that information to fuel future campaigns.\n",
    "\n",
    "Additionally, with more historic data, I would conduct sentiment analysis on each brand and compare this against any PR 'wins or losses' for that brand. For example, Nike's ad featuring Colin Kaepernick had very mixed feedback from the public depeding on where a particular person stands on some political issues. Likewise, Adidas released a sneaker for Black History Month that was entirely white in color, which also had varying feedback. Comparing the sentiment of posts with timestamps that coincide with these events could help the company analyze the full impact that each event had on their brand. I also would look at each brand compared to Under Armour, which has much less international recognition and less history. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Josh Robin - shared the function that was used to pull the data from Reddit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
